{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952faac1-56d0-478b-85b2-fc4b29f9ee8b",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3eb97a6-c0f9-4a76-9d5f-705505782df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#nltk.download('wordnet')\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import csv\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7af3c8-f302-4b15-a024-3d9b41d96b5c",
   "metadata": {},
   "source": [
    "# Code for our script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afaf4140-9914-4b69-8a03-0e86ef66b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainfile = 'c:/users/desir/Desktop/text_mining/applied TM/SEM-2012-SharedTask-CD-SCO-training-simple.v2.features.conll'\n",
    "testfile = 'c:/users/desir/Desktop/text_mining/applied TM/SEM-2012-SharedTask-CD-SCO-dev-simple.v2.features.conll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e8d09973-086f-4ad9-b771-b57198c702f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizer_and_classifier(features, labels):\n",
    "    '''\n",
    "    Function that takes feature-value pairs and gold labels as input and trains a logistic regression classifier\n",
    "    \n",
    "    :param features: feature-value pairs\n",
    "    :param labels: gold labels\n",
    "    :type features: a list of dictionaries\n",
    "    :type labels: a list of strings\n",
    "    \n",
    "    :return lr_classifier: a trained LogisticRegression classifier\n",
    "    :return vec: a DictVectorizer to which the feature values are fitted. \n",
    "    '''\n",
    "    \n",
    "    vec = DictVectorizer()\n",
    "    #fit creates a mapping between observed feature values and dimensions in a one-hot vector, transform represents the current values as a vector \n",
    "    tokens_vectorized = vec.fit_transform(features)\n",
    "    svm_classifier = LinearSVC()\n",
    "    svm_classifier.fit(tokens_vectorized, labels)\n",
    "    \n",
    "    return svm_classifier, vec\n",
    "\n",
    "def print_confusion_matrix(predictions, goldlabels):\n",
    "    '''\n",
    "    Function that prints out a confusion matrix\n",
    "    \n",
    "    :param predictions: predicted labels\n",
    "    :param goldlabels: gold standard labels\n",
    "    :type predictions, goldlabels: list of strings\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #based on example from https://datatofish.com/confusion-matrix-python/ \n",
    "    data = {'Gold':    goldlabels[1:], 'Predicted': predictions[1:]    }\n",
    "    df = pd.DataFrame(data, columns=['Gold','Predicted'])\n",
    "\n",
    "    confusion_matrix = pd.crosstab(df['Gold'], df['Predicted'], rownames=['Gold'], colnames=['Predicted'])\n",
    "    print (confusion_matrix)\n",
    "\n",
    "\n",
    "def print_precision_recall_fscore(predictions, goldlabels):\n",
    "    '''\n",
    "    Function that prints out precision, recall and f-score\n",
    "    \n",
    "    :param predictions: predicted output by classifier\n",
    "    :param goldlabels: original gold labels\n",
    "    :type predictions, goldlabels: list of strings\n",
    "    '''\n",
    "    \n",
    "    precision = metrics.precision_score(y_true=goldlabels,\n",
    "                        y_pred=predictions,\n",
    "                        average='macro')\n",
    "\n",
    "    recall = metrics.recall_score(y_true=goldlabels,\n",
    "                     y_pred=predictions,\n",
    "                     average='macro')\n",
    "\n",
    "\n",
    "    fscore = metrics.f1_score(y_true=goldlabels,\n",
    "                 y_pred=predictions,\n",
    "                 average='macro')\n",
    "\n",
    "    print('P:', precision, 'R:', recall, 'F1:', fscore)\n",
    "    \n",
    "#vectorizer and lr_classifier are the vectorizer and classifiers created in the previous cell.\n",
    "#it is important that the same vectorizer is used for both training and testing: they should use the same mapping from values to dimensions\n",
    "# predictions, goldlabels = get_predicted_and_gold_labels_token_only(testfile, vectorizer, lr_classifier)\n",
    "# print_confusion_matrix(predictions, goldlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fa1334fe-a7b8-490c-88d0-926260e42392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  B-NEG  I-NEG      O\n",
      "Gold                          \n",
      "B-NEG        171      0      5\n",
      "I-NEG          0      2      1\n",
      "O              7      0  13380\n",
      "P: 0.9867419870974384 R: 0.8792449064894537 F1: 0.921872055790301\n"
     ]
    }
   ],
   "source": [
    "# the functions with multiple features and analysis\n",
    "\n",
    "#defines the column in which each feature is located (note: you can also define headers and use csv.DictReader)\n",
    "#feature_to_index = {'TOKEN': 0, 'POS': 1, 'LEMMA': 2, 'PUNCTUATION': 3, 'STARTSWITH_CAPITAL_LETTER': 4, 'IS_STOPWORD': 5}\n",
    "\n",
    "\n",
    "def extract_features_and_gold_labels(conllfile, selected_features):\n",
    "    '''Function that extracts features and gold label from preprocessed conll (here: tokens only).\n",
    "    \n",
    "    :param conllfile: path to the (preprocessed) conll file\n",
    "    :type conllfile: string\n",
    "    \n",
    "    \n",
    "    :return features: a list of dictionaries, with key-value pair providing the value for the feature `token' for individual instances\n",
    "    :return labels: a list of gold labels of individual instances\n",
    "    '''\n",
    "    feature_to_index = {'Token': 3 , 'Pre-token': 5, 'Next-token': 6, 'Lemma':7 , 'Pre-lemma':8 , 'Next-lemma':9, 'POS':10, 'Pre-POS':11 , 'Next-POS':12 , 'POS_classified':13 , 'Punctuation_python': 14, 'MatchesNegExp': 15, 'HasNegAffix':16, 'Negated event':17, 'NegAffix':18}\n",
    "    features = []\n",
    "    labels = []\n",
    "    conllinput = open(conllfile, 'r')\n",
    "    #delimiter indicates we are working with a tab separated value (default is comma)\n",
    "    #quotechar has as default value '\"', which is used to indicate the borders of a cell containing longer pieces of text\n",
    "    #in this file, we have only one token as text, but this token can be '\"', which then messes up the format. We set quotechar to a character that does not occur in our file\n",
    "    csvreader = csv.reader(conllinput, delimiter='\\t',quotechar='|')\n",
    "    next(csvreader, None)\n",
    "    for row in csvreader:\n",
    "        #I preprocessed the file so that all rows with instances should contain 6 values, the others are empty lines indicating the beginning of a sentence\n",
    "        if len(row) > 0:\n",
    "            #structuring feature value pairs as key-value pairs in a dictionary\n",
    "            #the first column in the conll file represents tokens\n",
    "            feature_value = {}\n",
    "            for feature_name in selected_features:\n",
    "                row_index = feature_to_index.get(feature_name)\n",
    "                feature_value[feature_name] = row[row_index]\n",
    "            features.append(feature_value)\n",
    "            #The last column provides the gold label (= the correct answer). \n",
    "            labels.append(row[4])\n",
    "    return features, labels\n",
    "\n",
    "def get_predicted_and_gold_labels(testfile, vectorizer, classifier, selected_features):\n",
    "    '''\n",
    "    Function that extracts features and runs classifier on a test file returning predicted and gold labels\n",
    "    \n",
    "    :param testfile: path to the (preprocessed) test file\n",
    "    :param vectorizer: vectorizer in which the mapping between feature values and dimensions is stored\n",
    "    :param classifier: the trained classifier\n",
    "    :type testfile: string\n",
    "    :type vectorizer: DictVectorizer\n",
    "    :type classifier: LogisticRegression()\n",
    "    \n",
    "    \n",
    "    \n",
    "    :return predictions: list of output labels provided by the classifier on the test file\n",
    "    :return goldlabels: list of gold labels as included in the test file\n",
    "    '''\n",
    "    \n",
    "    #we use the same function as above (guarantees features have the same name and form)\n",
    "    features, goldlabels = extract_features_and_gold_labels(testfile, selected_features)\n",
    "    #we need to use the same fitting as before, so now we only transform the current features according to this mapping (using only transform)\n",
    "    test_features_vectorized = vectorizer.transform(features)\n",
    "    predictions = classifier.predict(test_features_vectorized)\n",
    "    \n",
    "    return predictions, goldlabels\n",
    "\n",
    "#define which from the available features will be used (names must match key names of dictionary feature_to_index)\n",
    "all_features = ['Token', 'Pre-token', 'Next-token', 'Lemma', 'Pre-lemma', 'Next-lemma', 'POS', 'Pre-POS', 'Next-POS', 'POS_classified', 'Punctuation_python', 'MatchesNegExp', 'HasNegAffix', 'Negated event', 'NegAffix']\n",
    "\n",
    "sparse_feature_reps, labels = extract_features_and_gold_labels(trainfile, all_features)\n",
    "#we can use the same function as before for creating the classifier and vectorizer\n",
    "svm_classifier, vectorizer = create_vectorizer_and_classifier(sparse_feature_reps, labels)\n",
    "#when applying our model to new data, we need to use the same features\n",
    "predictions, goldlabels = get_predicted_and_gold_labels(testfile, vectorizer, svm_classifier, all_features)\n",
    "print_confusion_matrix(predictions, goldlabels)\n",
    "print_precision_recall_fscore(predictions, goldlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4d78ea58-2f64-4696-b935-60e300d2ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(goldlabels,predictions,digits = 7, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf9be71b-ffc7-41af-81a8-56f5ce64f7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-NEG  0.9606742 0.9715909 0.9661017       176\n",
      "       I-NEG  1.0000000 0.6666667 0.8000000         3\n",
      "           O  0.9995518 0.9994771 0.9995145     13388\n",
      "\n",
      "    accuracy                      0.9990418     13567\n",
      "   macro avg  0.9867420 0.8792449 0.9218721     13567\n",
      "weighted avg  0.9990476 0.9990418 0.9990369     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aedc6273-a23f-4a6f-ac04-3d6aad3644ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted  B-NEG  I-NEG      O\n",
      "Gold                          \n",
      "B-NEG        173      0      3\n",
      "I-NEG          0      1      2\n",
      "O             13      0  13374\n",
      "P: 0.9765779449346642 R: 0.7717722866550174 F1: 0.8183762200874246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-NEG  0.9301075 0.9829545 0.9558011       176\n",
      "       I-NEG  1.0000000 0.3333333 0.5000000         3\n",
      "           O  0.9996263 0.9990290 0.9993276     13388\n",
      "\n",
      "    accuracy                      0.9986733     13567\n",
      "   macro avg  0.9765779 0.7717723 0.8183762     13567\n",
      "weighted avg  0.9987245 0.9986733 0.9986525     13567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example of system with just one additional feature\n",
    "#define which from the available features will be used (names must match key names of dictionary feature_to_index)\n",
    "selected_features = ['Token', 'Pre-token', 'Pre-lemma', 'Pre-POS', 'NegAffix']\n",
    "\n",
    "feature_values, labels = extract_features_and_gold_labels(trainfile, selected_features)\n",
    "#we can use the same function as before for creating the classifier and vectorizer\n",
    "svm_classifier, vectorizer = create_vectorizer_and_classifier(feature_values, labels)\n",
    "#when applying our model to new data, we need to use the same features\n",
    "predictions, goldlabels = get_predicted_and_gold_labels(testfile, vectorizer, svm_classifier, selected_features)\n",
    "print_confusion_matrix(predictions, goldlabels)\n",
    "print_precision_recall_fscore(predictions, goldlabels)\n",
    "report = classification_report(goldlabels,predictions,digits = 7, zero_division=0)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f891d14-de02-479c-b873-597c8128950c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
